{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/data_x/guro/DATA/ASCO_RAW\"\n",
    "save_dir = \"/data_x/guro/DATA/ASCO_RAW/CUSTOM_CHUNKS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_corpus_path = '/data_x/guro/DATA/ASCO_RAW/raw_corpus.parquet'\n",
    "df_raw = pd.read_parquet(raw_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>contents</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denosumab Prevents Bone Loss and Microarchitec...</td>\n",
       "      <td>Estradiol plays an important role in breast ca...</td>\n",
       "      <td>{'doc_authors': 'Sabashini K. Ramchand, MBBS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denosumab Prevents Bone Loss and Microarchitec...</td>\n",
       "      <td>This was a 12-month randomized, double-blind, ...</td>\n",
       "      <td>{'doc_authors': 'Sabashini K. Ramchand, MBBS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denosumab Prevents Bone Loss and Microarchitec...</td>\n",
       "      <td>Participants were stratified by lumbar spine B...</td>\n",
       "      <td>{'doc_authors': 'Sabashini K. Ramchand, MBBS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Denosumab Prevents Bone Loss and Microarchitec...</td>\n",
       "      <td>Participants received 60 mg DMAB or matching P...</td>\n",
       "      <td>{'doc_authors': 'Sabashini K. Ramchand, MBBS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denosumab Prevents Bone Loss and Microarchitec...</td>\n",
       "      <td>Adverse events were documented at each visit a...</td>\n",
       "      <td>{'doc_authors': 'Sabashini K. Ramchand, MBBS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>Cost-Effectiveness Analysis of No Adjuvant The...</td>\n",
       "      <td>The population modeled was similar to the popu...</td>\n",
       "      <td>{'doc_authors': 'Matthew C. Ward, MD https://o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>Cost-Effectiveness Analysis of No Adjuvant The...</td>\n",
       "      <td>Table 2presents the results from the base case...</td>\n",
       "      <td>{'doc_authors': 'Matthew C. Ward, MD https://o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7442</th>\n",
       "      <td>Cost-Effectiveness Analysis of No Adjuvant The...</td>\n",
       "      <td>One-way sensitivity analyses were performed to...</td>\n",
       "      <td>{'doc_authors': 'Matthew C. Ward, MD https://o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>Cost-Effectiveness Analysis of No Adjuvant The...</td>\n",
       "      <td>Probabilistic sensitivity analysis using Monte...</td>\n",
       "      <td>{'doc_authors': 'Matthew C. Ward, MD https://o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>Cost-Effectiveness Analysis of No Adjuvant The...</td>\n",
       "      <td>Our Markov microsimulation model for postmenop...</td>\n",
       "      <td>{'doc_authors': 'Matthew C. Ward, MD https://o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7445 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 doc_id  \\\n",
       "0     Denosumab Prevents Bone Loss and Microarchitec...   \n",
       "1     Denosumab Prevents Bone Loss and Microarchitec...   \n",
       "2     Denosumab Prevents Bone Loss and Microarchitec...   \n",
       "3     Denosumab Prevents Bone Loss and Microarchitec...   \n",
       "4     Denosumab Prevents Bone Loss and Microarchitec...   \n",
       "...                                                 ...   \n",
       "7440  Cost-Effectiveness Analysis of No Adjuvant The...   \n",
       "7441  Cost-Effectiveness Analysis of No Adjuvant The...   \n",
       "7442  Cost-Effectiveness Analysis of No Adjuvant The...   \n",
       "7443  Cost-Effectiveness Analysis of No Adjuvant The...   \n",
       "7444  Cost-Effectiveness Analysis of No Adjuvant The...   \n",
       "\n",
       "                                               contents  \\\n",
       "0     Estradiol plays an important role in breast ca...   \n",
       "1     This was a 12-month randomized, double-blind, ...   \n",
       "2     Participants were stratified by lumbar spine B...   \n",
       "3     Participants received 60 mg DMAB or matching P...   \n",
       "4     Adverse events were documented at each visit a...   \n",
       "...                                                 ...   \n",
       "7440  The population modeled was similar to the popu...   \n",
       "7441  Table 2presents the results from the base case...   \n",
       "7442  One-way sensitivity analyses were performed to...   \n",
       "7443  Probabilistic sensitivity analysis using Monte...   \n",
       "7444  Our Markov microsimulation model for postmenop...   \n",
       "\n",
       "                                               metadata  \n",
       "0     {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...  \n",
       "1     {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...  \n",
       "2     {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...  \n",
       "3     {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...  \n",
       "4     {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...  \n",
       "...                                                 ...  \n",
       "7440  {'doc_authors': 'Matthew C. Ward, MD https://o...  \n",
       "7441  {'doc_authors': 'Matthew C. Ward, MD https://o...  \n",
       "7442  {'doc_authors': 'Matthew C. Ward, MD https://o...  \n",
       "7443  {'doc_authors': 'Matthew C. Ward, MD https://o...  \n",
       "7444  {'doc_authors': 'Matthew C. Ward, MD https://o...  \n",
       "\n",
       "[7445 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. 문장 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /mnt/raid6/yjoonjang/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: \n",
      "Python is an interpreted, high-level, general-purpose programming language.\n",
      "Chunk 2: Its design philosophy emphasizes code readability.\n",
      "Chunk 3: It is widely used in various domains such as web development, data analysis, and AI.\n"
     ]
    }
   ],
   "source": [
    "# NLTK 설치\n",
    "# pip install nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "# 텍스트 파일 읽기\n",
    "text = \"\"\"\n",
    "Python is an interpreted, high-level, general-purpose programming language.\n",
    "Its design philosophy emphasizes code readability.\n",
    "It is widely used in various domains such as web development, data analysis, and AI.\n",
    "\"\"\"\n",
    "\n",
    "# 문장을 토큰화\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# 특정 크기로 청킹 (예: 2문장씩)\n",
    "chunk_size = 1\n",
    "chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]\n",
    "\n",
    "# 결과 출력\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {' '.join(chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_data = []\n",
    "\n",
    "for index, data in enumerate(df_raw[\"contents\"]):\n",
    "    sentences = sent_tokenize(data)\n",
    "    chunks = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunked_data.append({\n",
    "            \"contents\": \" \".join(chunk),\n",
    "            \"metadata\": df_raw[\"metadata\"][index],\n",
    "            \"doc_id\": df_raw[\"doc_id\"][index]\n",
    "        })\n",
    "\n",
    "\n",
    "chunked_df = pd.DataFrame(chunked_data)\n",
    "chunked_df.to_parquet(save_dir + \"/sentence_chunks.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            contents  \\\n",
      "0  Estradiol plays an important role in breast ca...   \n",
      "1  Adjuvant endocrine therapies prevent breast ca...   \n",
      "2  In premenopausal women with ER-positive early-...   \n",
      "3  This was a 12-month randomized, double-blind, ...   \n",
      "4  Premenopausal women, between age 18 and 55 yea...   \n",
      "\n",
      "                                            metadata  \\\n",
      "0  {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...   \n",
      "1  {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...   \n",
      "2  {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...   \n",
      "3  {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...   \n",
      "4  {'doc_authors': 'Sabashini K. Ramchand, MBBS, ...   \n",
      "\n",
      "                                              doc_id  \n",
      "0  Denosumab Prevents Bone Loss and Microarchitec...  \n",
      "1  Denosumab Prevents Bone Loss and Microarchitec...  \n",
      "2  Denosumab Prevents Bone Loss and Microarchitec...  \n",
      "3  Denosumab Prevents Bone Loss and Microarchitec...  \n",
      "4  Denosumab Prevents Bone Loss and Microarchitec...  \n"
     ]
    }
   ],
   "source": [
    "# 저장한 데이터 보기\n",
    "loaded_chunked_df = pd.read_parquet(save_dir + \"/sentence_chunks.parquet\")\n",
    "print(loaded_chunked_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 단어 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000_200\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter_1000_200 = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "text_splitter_500_100 = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "text_splitter_300_50 = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_data_1000 = []\n",
    "chunked_data_500 = []\n",
    "chunked_data_300 = []\n",
    "\n",
    "for index, data in enumerate(df_raw[\"contents\"]):\n",
    "    chunks_1000 = text_splitter_1000_200.split_text(data)\n",
    "    chunks_500 = text_splitter_500_100.split_text(data)\n",
    "    chunks_300 = text_splitter_300_50.split_text(data)\n",
    "    for chunk in chunks_1000:\n",
    "        chunked_data_1000.append({\n",
    "            \"contents\": chunk,\n",
    "            \"metadata\": df_raw[\"metadata\"][index],\n",
    "            \"doc_id\": df_raw[\"doc_id\"][index]\n",
    "        })\n",
    "    for chunk in chunks_500:\n",
    "        chunked_data_500.append({\n",
    "            \"contents\": chunk,\n",
    "            \"metadata\": df_raw[\"metadata\"][index],\n",
    "            \"doc_id\": df_raw[\"doc_id\"][index]\n",
    "        })\n",
    "    for chunk in chunks_300:\n",
    "        chunked_data_300.append({\n",
    "            \"contents\": chunk,\n",
    "            \"metadata\": df_raw[\"metadata\"][index],\n",
    "            \"doc_id\": df_raw[\"doc_id\"][index]\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_df_1000 = pd.DataFrame(chunked_data_1000)\n",
    "chunked_df_500 = pd.DataFrame(chunked_data_500)\n",
    "chunked_df_300 = pd.DataFrame(chunked_data_300)\n",
    "\n",
    "chunked_df_1000.to_parquet(save_dir + \"/word_chunks_1000_200.parquet\")\n",
    "chunked_df_500.to_parquet(save_dir + \"/word_chunks_500_100.parquet\")\n",
    "chunked_df_300.to_parquet(save_dir + \"/word_chunks_300_50.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autorag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
